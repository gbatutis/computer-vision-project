{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/ext3/miniconda3/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torcheval.metrics.functional import multiclass_f1_score\n",
    "from torchvision import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset class to create dataloader for train, val and test\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, images, labels):\n",
    "        # Convert images and labels to PyTorch tensors\n",
    "        self.images = torch.tensor(images, dtype=torch.float32)\n",
    "        # self.images = self.images.view(batch_size, num_channels, 50, 50)\n",
    "        self.labels = torch.tensor(labels, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "        return image, label\n",
    "\n",
    "# Assemble datasets with dataloader\n",
    "def get_dataset(batch_size, train_images, train_labels, val_images, val_labels):\n",
    "    \n",
    "    train_dataset = MyDataset(images = train_images, labels = train_labels) \n",
    "    val_dataset = MyDataset(images = val_images, labels= val_labels)\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "      train_dataset, batch_size=batch_size, shuffle=True, num_workers=1)\n",
    "    val_loader = DataLoader(\n",
    "      val_dataset, batch_size=batch_size, shuffle=True, num_workers=1)\n",
    "\n",
    "    return train_dataset, train_loader, val_dataset, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_model_layers(model, num_channels, num_classes):\n",
    "    num_ftrs = model.fc.in_features\n",
    "\n",
    "    # Change size of initial layer to match input size of satelite imagery\n",
    "    model.conv1 = nn.Conv2d(num_channels, model.conv1.out_channels,\n",
    "                                kernel_size=model.conv1.kernel_size,\n",
    "                                stride=model.conv1.stride,\n",
    "                                padding=model.conv1.padding,\n",
    "                                bias=False)\n",
    "\n",
    "    # change size of final output layer of model\n",
    "    model.fc = nn.Linear(num_ftrs, num_classes)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_images = np.load('train_humans.npz')['arr_0']\n",
    "train_labels = np.load('train_labels_humans.npz')['arr_0']\n",
    "val_images = np.load('val_humans.npz')['arr_0']\n",
    "val_labels = np.load('val_labels_humans.npz')['arr_0']\n",
    "num_classes = len(np.unique(val_labels))\n",
    "num_channels = train_images.shape[1]\n",
    "\n",
    "human_train_dataset, human_train_loader, human_val_dataset, human_val_loader = get_dataset(batch_size, train_images, train_labels, val_images, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/mcs9834/.cache/torch/hub/moskomule_senet.pytorch_master\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bring in model\n",
    "model = torch.hub.load('moskomule/senet.pytorch','se_resnet20', num_classes=num_classes)\n",
    "model = update_model_layers(model, num_channels, num_classes)\n",
    "\n",
    "model.load_state_dict(torch.load('dual_split/model:se_resnet20_epoch:3_lr:0.03_mom:0.9_step:15_gamma:0.3_valloss:2.9_f1loss:0.72_batchsize:32_binary:humans.pt'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation set: Average loss: 2.9038, Accuracy: 2723/4864 (56%)\n",
      "\n",
      "val_loss 2.9038045406341553 f1_loss: tensor(0.7158)\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "validation_loss = 0\n",
    "correct = 0\n",
    "y_true = []\n",
    "y_pred = []\n",
    "for data, target in human_val_loader:\n",
    "    y_true.append(target)\n",
    "    #change data sizing here if it comes in in the correct size\n",
    "    output = model(data)#.view(batch_size, 98, 50, 50)\n",
    "    validation_loss += F.cross_entropy(output, target, reduction='sum')\n",
    "    pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "    y_pred.append(torch.flatten(pred))\n",
    "    correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "\n",
    "# change number of classes if switching to binary classification\n",
    "y_true = torch.cat(y_true)\n",
    "y_pred = torch.cat(y_pred)\n",
    "f1 = multiclass_f1_score(y_true, y_pred, average='weighted', num_classes = num_classes)\n",
    "validation_loss /= len(human_val_loader.dataset)\n",
    "print('\\nValidation set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "    validation_loss, correct, len(human_val_loader.dataset),\n",
    "    100. * correct / len(human_val_loader.dataset)))\n",
    "print('val_loss', validation_loss.item(), 'f1_loss:', f1.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1,  ..., 1, 1, 1])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_humans = y_pred.detach().clone()\n",
    "y_pred_humans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_images = np.load('train_electricity.npz')['arr_0']\n",
    "train_labels = np.load('train_labels_electricity.npz')['arr_0']\n",
    "val_images = np.load('val_electricity.npz')['arr_0']\n",
    "val_labels = np.load('val_labels_electricity.npz')['arr_0']\n",
    "num_classes = len(np.unique(val_labels))\n",
    "num_channels = train_images.shape[1]\n",
    "\n",
    "elec_train_dataset, elec_train_loader, elec_val_dataset, elec_val_loader = get_dataset(batch_size, train_images, train_labels, val_images, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/mcs9834/.cache/torch/hub/moskomule_senet.pytorch_master\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bring in model\n",
    "num_classes = len(np.unique(val_labels))\n",
    "model_elec = torch.hub.load('moskomule/senet.pytorch','se_resnet20', num_classes=num_classes)\n",
    "model_elec = update_model_layers(model, num_channels, num_classes)\n",
    "\n",
    "model_elec.load_state_dict(torch.load('dual_split/model:se_resnet20_epoch:1_lr:0.03_mom:0.9_step:15_gamma:0.3_valloss:0.08_f1loss:0.99_batchsize:32_binary:elec.pt'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Warning: Some classes do not exist in the target. F1 scores for these classes will be cast to zeros.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation set: Average loss: 0.0767, Accuracy: 4789/4864 (98%)\n",
      "\n",
      "val_loss 0.07669061422348022 f1_loss: 0.9922304153442383\n"
     ]
    }
   ],
   "source": [
    "model_elec.eval()\n",
    "validation_loss = 0\n",
    "correct = 0\n",
    "y_true = []\n",
    "y_pred = []\n",
    "for data, target in elec_val_loader:\n",
    "    y_true.append(target)\n",
    "    #change data sizing here if it comes in in the correct size\n",
    "    output = model_elec(data)#.view(batch_size, 98, 50, 50)\n",
    "    validation_loss += F.cross_entropy(output, target, reduction='sum')\n",
    "    pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "    y_pred.append(torch.flatten(pred))\n",
    "    correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "\n",
    "# change number of classes if switching to binary classification\n",
    "y_true = torch.cat(y_true)\n",
    "y_pred = torch.cat(y_pred)\n",
    "f1 = multiclass_f1_score(y_true, y_pred, average='weighted', num_classes = num_classes)\n",
    "validation_loss /= len(elec_val_loader.dataset)\n",
    "print('\\nValidation set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "    validation_loss, correct, len(elec_val_loader.dataset),\n",
    "    100. * correct / len(elec_val_loader.dataset)))\n",
    "print('val_loss', validation_loss.item(), 'f1_loss:', f1.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0,  ..., 0, 0, 0])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_elec = y_pred.detach().clone()\n",
    "y_pred_elec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_dual_split = np.zeros(len(y_pred_humans))\n",
    "y_pred_dual_split.fill(5) #making these 5 to ensure only 0s and 1s get filled and not left over\n",
    "\n",
    "for i in range(len((y_pred_humans))): \n",
    "    if y_pred_humans == 1 and y_pred_elec == 0: \n",
    "        y_pred_dual_split[i] = 0\n",
    "    elif y_pred_humans == 0 and y_pred_elec == 0:\n",
    "        y_pred_dual_split[i] = 1\n",
    "    elif y_pred_humans == 1 and y_pred_elec == 1:\n",
    "        y_pred_dual_split[i] = 2\n",
    "    elif y_pred_humans == 0 and y_pred_elec == 1:\n",
    "        y_pred_dual_split[i] = 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1,  ..., 0, 1, 1])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Need 2 sats val loader to check for comparison\n",
    "val_labels_all = torch.from_numpy(np.load('val_labels2.npz')['labels'])\n",
    "val_labels_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0,  ..., 0, 0, 0])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_dual_split = torch.from_numpy(y_pred_dual_split.astype('int64'))\n",
    "y_pred_dual_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Warning: Some classes do not exist in the target. F1 scores for these classes will be cast to zeros.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7094720005989075"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Num classes = 4\n",
    "num_classes = 4\n",
    "f1 = multiclass_f1_score(val_labels_all, y_pred_dual_split, average='weighted', num_classes = num_classes)\n",
    "f1.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking dual model - 2sats data for each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "val_images = np.load('val_data_2sats.npz')['arr_0']\n",
    "val_labels_human = np.load('val_labels_humans.npz')['arr_0']\n",
    "val_labels_elec = np.load('val_labels_electricity.npz')['arr_0']\n",
    "\n",
    "val_dataset_human = MyDataset(images = val_images, labels= val_labels_human)\n",
    "val_dataset_elec = MyDataset(images = val_images, labels= val_labels_elec)\n",
    "\n",
    "val_loader_humans = DataLoader(val_dataset_human, batch_size=batch_size, shuffle=True, num_workers=1)\n",
    "val_loader_elec = DataLoader(val_dataset_elec, batch_size=batch_size, shuffle=True, num_workers=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/mcs9834/.cache/torch/hub/moskomule_senet.pytorch_master\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_channels = val_images.shape[1]\n",
    "num_classes = len(np.unique(val_labels_human))\n",
    "model = torch.hub.load('moskomule/senet.pytorch','se_resnet20', num_classes=num_classes)\n",
    "model = update_model_layers(model, num_channels, num_classes)\n",
    "\n",
    "model.load_state_dict(torch.load('dual_split/model:se_resnet20_epoch:3_lr:0.005_mom:0.9_step:15_gamma:0.3_valloss:1.01_f1loss:0.7_batchsize:64_binary:humans.pt'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation set: Average loss: 1.0065, Accuracy: 2685/4864 (55%)\n",
      "\n",
      "val_loss 1.0065159797668457 f1_loss: 0.7006344795227051\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "validation_loss = 0\n",
    "correct = 0\n",
    "y_true = []\n",
    "y_pred = []\n",
    "for data, target in val_loader_humans:\n",
    "    y_true.append(target)\n",
    "    #change data sizing here if it comes in in the correct size\n",
    "    output = model(data)#.view(batch_size, 98, 50, 50)\n",
    "    validation_loss += F.cross_entropy(output, target, reduction='sum')\n",
    "    pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "    y_pred.append(torch.flatten(pred))\n",
    "    correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "\n",
    "# change number of classes if switching to binary classification\n",
    "y_true = torch.cat(y_true)\n",
    "y_pred = torch.cat(y_pred)\n",
    "f1 = multiclass_f1_score(y_true, y_pred, average='weighted', num_classes = num_classes)\n",
    "validation_loss /= len(val_loader_humans.dataset)\n",
    "print('\\nValidation set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "    validation_loss, correct, len(val_loader_humans.dataset),\n",
    "    100. * correct / len(val_loader_humans.dataset)))\n",
    "print('val_loss', validation_loss.item(), 'f1_loss:', f1.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1,  ..., 1, 1, 1])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_humans_dual = y_pred.detach().clone()\n",
    "y_pred_humans_dual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/mcs9834/.cache/torch/hub/moskomule_senet.pytorch_master\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bring in model\n",
    "num_classes = len(np.unique(val_labels_elec))\n",
    "num_channels = val_images.shape[1]\n",
    "model_elec = torch.hub.load('moskomule/senet.pytorch','se_resnet20', num_classes=num_classes)\n",
    "model_elec = update_model_layers(model, num_channels, num_classes)\n",
    "\n",
    "model_elec.load_state_dict(torch.load('model:se_resnet20_epoch:1_lr:0.03_mom:0.9_step:15_gamma:0.3_valloss:0.08_f1loss:0.99_batchsize:32_binary:elec.pt'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Warning: Some classes do not exist in the target. F1 scores for these classes will be cast to zeros.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation set: Average loss: 0.0801, Accuracy: 4789/4864 (98%)\n",
      "\n",
      "val_loss 0.0800526887178421 f1_loss: 0.9922304153442383\n"
     ]
    }
   ],
   "source": [
    "model_elec.eval()\n",
    "validation_loss = 0\n",
    "correct = 0\n",
    "y_true = []\n",
    "y_pred = []\n",
    "for data, target in val_loader_elec:\n",
    "    y_true.append(target)\n",
    "    #change data sizing here if it comes in in the correct size\n",
    "    output = model_elec(data)#.view(batch_size, 98, 50, 50)\n",
    "    validation_loss += F.cross_entropy(output, target, reduction='sum')\n",
    "    pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "    y_pred.append(torch.flatten(pred))\n",
    "    correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "\n",
    "# change number of classes if switching to binary classification\n",
    "y_true = torch.cat(y_true)\n",
    "y_pred = torch.cat(y_pred)\n",
    "f1 = multiclass_f1_score(y_true, y_pred, average='weighted', num_classes = num_classes)\n",
    "validation_loss /= len(val_loader_elec.dataset)\n",
    "print('\\nValidation set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "    validation_loss, correct, len(val_loader_elec.dataset),\n",
    "    100. * correct / len(val_loader_elec.dataset)))\n",
    "print('val_loss', validation_loss.item(), 'f1_loss:', f1.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0,  ..., 0, 0, 0])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_elec_dual = y_pred.detach().clone()\n",
    "y_pred_elec_dual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_dual = np.zeros(len(y_pred_humans_dual))\n",
    "y_pred_dual.fill(5) #making these 5 to ensure only 0s and 1s get filled and not left over\n",
    "\n",
    "for i in range(len((y_pred_humans_dual))): \n",
    "    if y_pred_humans_dual[i] == 1 and y_pred_elec_dual[i] == 0: \n",
    "        y_pred_dual[i] = 0\n",
    "    elif y_pred_humans_dual[i] == 0 and y_pred_elec_dual[i] == 0:\n",
    "        y_pred_dual[i] = 1\n",
    "    elif y_pred_humans_dual[i] == 1 and y_pred_elec_dual[i] == 1:\n",
    "        y_pred_dual[i] = 2\n",
    "    elif y_pred_humans_dual[i] == 0 and y_pred_elec_dual[i] == 1:\n",
    "        y_pred_dual[i] = 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1,  ..., 0, 1, 1])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Need 2 sats val loader to check for comparison\n",
    "val_labels_all = torch.from_numpy(np.load('val_labels2.npz')['labels'])\n",
    "val_labels_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0,  ..., 0, 0, 0])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_dual = torch.from_numpy(y_pred_dual.astype('int64'))\n",
    "y_pred_dual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Warning: Some classes do not exist in the target. F1 scores for these classes will be cast to zeros.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6956865787506104"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Num classes = 4\n",
    "num_classes = 4\n",
    "f1 = multiclass_f1_score(val_labels_all, y_pred_dual, average='weighted', num_classes = num_classes)\n",
    "f1.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "humans:  model:se_resnet20_epoch:3_lr:0.005_mom:0.9_step:15_gamma:0.3_valloss:1.01_f1loss:0.7_batchsize:64_binary:humans.pt\n",
    "                                        \n",
    "elec: model:se_resnet20_epoch:1_lr:0.03_mom:0.9_step:15_gamma:0.3_valloss:0.08_f1loss:0.99_batchsize:32_binary:elec.pt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "my_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
